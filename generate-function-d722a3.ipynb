{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-08T17:30:00.191224Z",
     "iopub.status.busy": "2022-10-08T17:30:00.190679Z",
     "iopub.status.idle": "2022-10-08T17:30:00.419907Z",
     "shell.execute_reply": "2022-10-08T17:30:00.418484Z",
     "shell.execute_reply.started": "2022-10-08T17:30:00.191116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eba0eb3aa64c6a800aab1adb2e7de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !huggingface-cli login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:34:27.069016Z",
     "iopub.status.busy": "2022-10-08T17:34:27.068040Z",
     "iopub.status.idle": "2022-10-08T17:35:12.937471Z",
     "shell.execute_reply": "2022-10-08T17:35:12.936065Z",
     "shell.execute_reply.started": "2022-10-08T17:34:27.068958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: SentencePiece in /opt/conda/lib/python3.7/site-packages (0.1.97)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openpyxl in /opt/conda/lib/python3.7/site-packages (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.7/site-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlsxwriter in /opt/conda/lib/python3.7/site-packages (3.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install SentencePiece\n",
    "!pip install openpyxl\n",
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:35:12.940453Z",
     "iopub.status.busy": "2022-10-08T17:35:12.940016Z",
     "iopub.status.idle": "2022-10-08T17:37:02.870564Z",
     "shell.execute_reply": "2022-10-08T17:37:02.868235Z",
     "shell.execute_reply.started": "2022-10-08T17:35:12.940404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'xl-sum'...\n",
      "remote: Enumerating objects: 1156, done.\u001b[K\n",
      "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
      "remote: Total 1156 (delta 19), reused 30 (delta 12), pack-reused 1109\u001b[K\n",
      "Receiving objects: 100% (1156/1156), 5.53 MiB | 12.05 MiB/s, done.\n",
      "Resolving deltas: 100% (309/309), done.\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/seq2seq/requirements.txt (line 1)) (2.10.0)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/seq2seq/requirements.txt (line 2)) (1.0.2)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/seq2seq/requirements.txt (line 4)) (5.9.1)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu\n",
      "  Downloading sacrebleu-2.2.1-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/seq2seq/requirements.txt (line 6)) (0.1.97)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/seq2seq/requirements.txt (line 7)) (3.19.4)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.21.7-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (59.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.35.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.43.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.15.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (2.2.2)\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./xl-sum/seq2seq/requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./xl-sum/seq2seq/requirements.txt (line 2)) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->-r ./xl-sum/seq2seq/requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu->-r ./xl-sum/seq2seq/requirements.txt (line 5)) (4.9.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu->-r ./xl-sum/seq2seq/requirements.txt (line 5)) (0.8.10)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu->-r ./xl-sum/seq2seq/requirements.txt (line 5)) (2021.11.10)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu->-r ./xl-sum/seq2seq/requirements.txt (line 5)) (2.5.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu->-r ./xl-sum/seq2seq/requirements.txt (line 5)) (0.4.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (4.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (1.26.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./xl-sum/seq2seq/requirements.txt (line 1)) (3.2.0)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a0a3e9237a8a3a9173bcdf2b84135ac81f94383b03e9ac32ab9d4a6e00ca282a\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built seqeval\n",
      "Installing collected packages: sacrebleu, psutil, protobuf, seqeval, tensorboard\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.1\n",
      "    Uninstalling psutil-5.9.1:\n",
      "      Successfully uninstalled psutil-5.9.1\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.10.0\n",
      "    Uninstalling tensorboard-2.10.0:\n",
      "      Successfully uninstalled tensorboard-2.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\n",
      "tfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\n",
      "tfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.3.0 which is incompatible.\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\n",
      "nnabla 1.29.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.19.6 which is incompatible.\n",
      "grpcio-status 1.47.0 requires grpcio>=1.47.0, but you have grpcio 1.43.0 which is incompatible.\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.7.1 which is incompatible.\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.19.6 psutil-5.9.2 sacrebleu-2.2.1 seqeval-1.2.2 tensorboard-2.10.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Invalid requirement: 'transformers/'\n",
      "Hint: It looks like a path. File 'transformers/' does not exist.\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting git+https://github.com/otuncelli/turkish-stemmer-python (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 1))\n",
      "  Cloning https://github.com/otuncelli/turkish-stemmer-python to /tmp/pip-req-build-ycw7lbiy\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/otuncelli/turkish-stemmer-python /tmp/pip-req-build-ycw7lbiy\n",
      "  Resolved https://github.com/otuncelli/turkish-stemmer-python to commit 0c22380bf84a5ab1f219f4a905274c78afa04ed1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting git+https://github.com/abhik1505040/bengali-stemmer (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 2))\n",
      "  Cloning https://github.com/abhik1505040/bengali-stemmer to /tmp/pip-req-build-6r7z4kbr\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/abhik1505040/bengali-stemmer /tmp/pip-req-build-6r7z4kbr\n",
      "  Resolved https://github.com/abhik1505040/bengali-stemmer to commit 375186caee8e50e3260dd6bc02d20d50277f3e39\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 3)) (0.15.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 5)) (1.21.6)\n",
      "Requirement already satisfied: six>=1.14 in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 6)) (1.15.0)\n",
      "Collecting pythainlp\n",
      "  Downloading pythainlp-3.1.0-py3-none-any.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyonmttok\n",
      "  Downloading pyonmttok-1.34.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jieba in /opt/conda/lib/python3.7/site-packages (from -r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 9)) (0.42.1)\n",
      "Collecting fugashi[unidic]\n",
      "  Downloading fugashi-1.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (583 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.5/583.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.7/site-packages (from pythainlp->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 7)) (2.28.1)\n",
      "Collecting unidic\n",
      "  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 7)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.22.0->pythainlp->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 7)) (1.26.11)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (4.12.0)\n",
      "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from unidic->fugashi[unidic]->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 10)) (0.10.1)\n",
      "Collecting plac<2.0.0,>=1.1.3\n",
      "  Downloading plac-1.3.5-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->-r ./xl-sum/multilingual_rouge_scoring/requirements.txt (line 4)) (3.8.0)\n",
      "Building wheels for collected packages: TurkishStemmer, bengali-stemmer, unidic\n",
      "  Building wheel for TurkishStemmer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for TurkishStemmer: filename=TurkishStemmer-1.3-py3-none-any.whl size=19871 sha256=6db51b83cddd2cfb0cd8cb3864ccb34a31cc1dcb3f40857e427de7bb88909525\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3n9vembu/wheels/ee/65/db/c127b9a272f949d5a421a9b7b43128aa8b1d143bafa52f10d1\n",
      "  Building wheel for bengali-stemmer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bengali-stemmer: filename=bengali_stemmer-0.0.1-py2.py3-none-any.whl size=6408 sha256=a9a5a96cfb3a0da2eaedebfd682e155100d9bba7223ff0594f622e8a454da719\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3n9vembu/wheels/6a/f4/ee/9298bdab6928b70071ca2876ff3950a7d4adb36ed489be77d2\n",
      "  Building wheel for unidic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7426 sha256=8484f3989237472d7ea315c03b8738be8eb53cf9854dc878ae446e5b6e379a60\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/4d/f1/170bb74b559ca338113c0315c9805e16dfd0a12411ec6b1122\n",
      "Successfully built TurkishStemmer bengali-stemmer unidic\n",
      "Installing collected packages: TurkishStemmer, plac, bengali-stemmer, pyonmttok, fugashi, unidic, pythainlp\n",
      "Successfully installed TurkishStemmer-1.3 bengali-stemmer-0.0.1 fugashi-1.2.0 plac-1.3.5 pyonmttok-1.34.0 pythainlp-3.1.0 unidic-1.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mdownload url: https://cotonoha-dic.s3-ap-northeast-1.amazonaws.com/unidic-3.1.0.zip\n",
      "Dictionary version: 3.1.0+2021-08-31\n",
      "Downloading UniDic v3.1.0+2021-08-31...\n",
      "unidic-3.1.0.zip: 100%|██████████████████████| 526M/526M [00:19<00:00, 26.9MB/s]\n",
      "Finished download.\n",
      "Downloaded UniDic v3.1.0+2021-08-31 to /opt/conda/lib/python3.7/site-packages/unidic/dicdir\n",
      "Processing ./xl-sum/multilingual_rouge_scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score==0.0.0) (0.15.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge-score==0.0.0) (3.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge-score==0.0.0) (1.21.6)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score==0.0.0) (1.15.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score==0.0.0) (2021.11.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score==0.0.0) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score==0.0.0) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score==0.0.0) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->nltk->rouge-score==0.0.0) (4.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->rouge-score==0.0.0) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->nltk->rouge-score==0.0.0) (3.8.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.0.0-py3-none-any.whl size=18182 sha256=df173caec1acc35c1acf28862dc23331c8ad6f7de363cf9efe5745b777116400\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jcd7rjvl/wheels/4f/07/35/339fd97dbcdebcdd6421137bf0930ce61a48e307e357213aa0\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/opt/conda/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/csebuetnlp/xl-sum\n",
    "! pip install --upgrade -r ./xl-sum/seq2seq/requirements.txt\n",
    "! pip install --upgrade transformers/\n",
    "# install rouge module and dependecies\n",
    "! pip install -r ./xl-sum/multilingual_rouge_scoring/requirements.txt\n",
    "! python -m unidic download # for japanese segmentation\n",
    "! pip install --upgrade ./xl-sum/multilingual_rouge_scoring\n",
    "! python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:37:14.846390Z",
     "iopub.status.busy": "2022-10-08T17:37:14.843893Z",
     "iopub.status.idle": "2022-10-08T17:37:14.853132Z",
     "shell.execute_reply": "2022-10-08T17:37:14.851645Z",
     "shell.execute_reply.started": "2022-10-08T17:37:14.846312Z"
    }
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import nltk\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:37:42.730301Z",
     "iopub.status.busy": "2022-10-08T17:37:42.729734Z",
     "iopub.status.idle": "2022-10-08T17:38:21.829937Z",
     "shell.execute_reply": "2022-10-08T17:38:21.828317Z",
     "shell.execute_reply.started": "2022-10-08T17:37:42.730265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b45e55d94349c3837777c9c2375285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2300bc350c3f45978bce1e468c8286a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6624bace59f74062a633ba9e1c904f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f710c20d418847709ebe2e33c00cc22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d3f96cddf74991ad2e43a8941b4297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be515633b0804a09b72d02625e2e4a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/945M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPT = 'jannatul17/squad-bn-qgen-banglat5'\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "tokenizer_test = AutoTokenizer.from_pretrained(CKPT, use_auth_token=False)\n",
    "model_test = T5ForConditionalGeneration.from_pretrained(CKPT, use_auth_token=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:41:10.630231Z",
     "iopub.status.busy": "2022-10-08T17:41:10.628726Z",
     "iopub.status.idle": "2022-10-08T17:41:39.100234Z",
     "shell.execute_reply": "2022-10-08T17:41:39.098975Z",
     "shell.execute_reply.started": "2022-10-08T17:41:10.630163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d0489d194f45688ec31a3b5147f5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_bn/squad_bn to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320f4b6e21b6455286d1950d48879107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.43M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_bn downloaded and prepared to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "train_data = load_dataset(\"csebuetnlp/squad_bn\", split=\"train\")\n",
    "valid_data = load_dataset(\"csebuetnlp/squad_bn\", split=\"validation\")\n",
    "test_data = load_dataset(\"csebuetnlp/squad_bn\", split=\"test\")\n",
    "\n",
    "concat_dataset = concatenate_datasets([train_data, valid_data, test_data])\n",
    "dataset=concat_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:41:40.369442Z",
     "iopub.status.busy": "2022-10-08T17:41:40.368945Z",
     "iopub.status.idle": "2022-10-08T17:41:40.376795Z",
     "shell.execute_reply": "2022-10-08T17:41:40.375103Z",
     "shell.execute_reply.started": "2022-10-08T17:41:40.369405Z"
    }
   },
   "outputs": [],
   "source": [
    "del concat_dataset, train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:41:41.666060Z",
     "iopub.status.busy": "2022-10-08T17:41:41.665329Z",
     "iopub.status.idle": "2022-10-08T17:41:49.840790Z",
     "shell.execute_reply": "2022-10-08T17:41:49.839849Z",
     "shell.execute_reply.started": "2022-10-08T17:41:41.666021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba461f443db40188d33317ab6895c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62eea335da51499a857110d0abe4a898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "small_dataset= dataset.filter(lambda example: len(example['answers']['text'])>0)\n",
    "small_dataset= small_dataset.filter(lambda example: len(example['context'])>300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:42:09.565889Z",
     "iopub.status.busy": "2022-10-08T17:42:09.565389Z",
     "iopub.status.idle": "2022-10-08T17:42:09.604974Z",
     "shell.execute_reply": "2022-10-08T17:42:09.603494Z",
     "shell.execute_reply.started": "2022-10-08T17:42:09.565851Z"
    }
   },
   "outputs": [],
   "source": [
    "split_data = small_dataset.train_test_split(test_size=0.2, seed= None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:42:19.414602Z",
     "iopub.status.busy": "2022-10-08T17:42:19.414168Z",
     "iopub.status.idle": "2022-10-08T17:42:19.420631Z",
     "shell.execute_reply": "2022-10-08T17:42:19.419289Z",
     "shell.execute_reply.started": "2022-10-08T17:42:19.414570Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:42:27.146267Z",
     "iopub.status.busy": "2022-10-08T17:42:27.145797Z",
     "iopub.status.idle": "2022-10-08T17:42:27.152724Z",
     "shell.execute_reply": "2022-10-08T17:42:27.151559Z",
     "shell.execute_reply.started": "2022-10-08T17:42:27.146221Z"
    }
   },
   "outputs": [],
   "source": [
    "del split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:42:40.311457Z",
     "iopub.status.busy": "2022-10-08T17:42:40.311033Z",
     "iopub.status.idle": "2022-10-08T17:42:40.318972Z",
     "shell.execute_reply": "2022-10-08T17:42:40.317216Z",
     "shell.execute_reply.started": "2022-10-08T17:42:40.311421Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_dataset(example):\n",
    "  \n",
    "        return {'input': 'answer: ' + example['answers']['text'][0] + ' context: ' + example['context'], 'target': example['question']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:05:53.965262Z",
     "iopub.status.busy": "2022-09-27T14:05:53.963912Z",
     "iopub.status.idle": "2022-09-27T14:06:17.519012Z",
     "shell.execute_reply": "2022-09-27T14:06:17.517498Z",
     "shell.execute_reply.started": "2022-09-27T14:05:53.965215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2999b5c0e24bf4aeeb821d4dfb1d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset squad_bn/squad_bn to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6311e470a3ff4036b42078b8bcf10dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.43M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset squad_bn downloaded and prepared to /root/.cache/huggingface/datasets/csebuetnlp___squad_bn/squad_bn/0.0.1/17a6d6abc976f299afda17ca9b5ce08a022ecafabe24b3362e16a3093c32df4b. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "#test_data = load_dataset('csebuetnlp/squad_bn', split='test')\n",
    "\n",
    "# small_dataset= test_data.filter(lambda example: len(example['answers']['text'])>0)\n",
    "# small_dataset= small_dataset.filter(lambda example: len(example['context'])>300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:06:17.521107Z",
     "iopub.status.busy": "2022-09-27T14:06:17.520744Z",
     "iopub.status.idle": "2022-09-27T14:06:17.528218Z",
     "shell.execute_reply": "2022-09-27T14:06:17.526815Z",
     "shell.execute_reply.started": "2022-09-27T14:06:17.521076Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_dataset(example):\n",
    "    if (len(example['answers']['text'])>0):\n",
    "        return {'input': 'answer: ' + example['answers']['text'][0] + ' context: ' + example['context'], 'target': example['question']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:42:59.401645Z",
     "iopub.status.busy": "2022-10-08T17:42:59.401147Z",
     "iopub.status.idle": "2022-10-08T17:43:13.130821Z",
     "shell.execute_reply": "2022-10-08T17:43:13.129943Z",
     "shell.execute_reply.started": "2022-10-08T17:42:59.401608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ba631f459e48ac98477cf98648162b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54150 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a3fe877ff6400581d6697da4ac0b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13538 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(format_dataset, remove_columns=dataset['train'].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:43:56.795712Z",
     "iopub.status.busy": "2022-10-08T17:43:56.795249Z",
     "iopub.status.idle": "2022-10-08T17:43:56.802701Z",
     "shell.execute_reply": "2022-10-08T17:43:56.800950Z",
     "shell.execute_reply.started": "2022-10-08T17:43:56.795676Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:43:35.106092Z",
     "iopub.status.busy": "2022-10-08T17:43:35.105579Z",
     "iopub.status.idle": "2022-10-08T17:43:35.113016Z",
     "shell.execute_reply": "2022-10-08T17:43:35.111553Z",
     "shell.execute_reply.started": "2022-10-08T17:43:35.106056Z"
    }
   },
   "outputs": [],
   "source": [
    "#dataset = test_data.map(format_dataset, remove_columns=test_data.column_names)\n",
    "\n",
    "# # dataset = test_data.map(format_dataset)\n",
    "#test_data['answers'][6]['text']\n",
    "#dataset[0]\n",
    "#small_dataset= dataset.filter(lambda example: len(example['answers']['text'])>0)\n",
    "# small_dataset= small_dataset.filter(lambda example: len(example['context'])>300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:44:09.965615Z",
     "iopub.status.busy": "2022-10-08T17:44:09.965156Z",
     "iopub.status.idle": "2022-10-08T17:44:09.973961Z",
     "shell.execute_reply": "2022-10-08T17:44:09.972071Z",
     "shell.execute_reply.started": "2022-10-08T17:44:09.965563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13538"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:44:44.574501Z",
     "iopub.status.busy": "2022-10-08T17:44:44.574051Z",
     "iopub.status.idle": "2022-10-08T17:44:44.584609Z",
     "shell.execute_reply": "2022-10-08T17:44:44.583106Z",
     "shell.execute_reply.started": "2022-10-08T17:44:44.574466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'answer: ১৯৮৭ context: ফলস্বরূপ, ১৯৭৯ সালে, সনি এবং ফিলিপস একটি নতুন ডিজিটাল অডিও ডিস্ক ডিজাইন করার জন্য প্রকৌশলীদের একটি যৌথ টাস্ক ফোর্স গঠন করে। ইঞ্জিনিয়ার কিস শুহামার ইমমিনক এবং তোশিতাদা দোই এর নেতৃত্বে, গবেষণাটি লেজার এবং অপটিক্যাল ডিস্ক প্রযুক্তিকে এগিয়ে নিয়ে যায়। এক বছর পরীক্ষা-নিরীক্ষা ও আলোচনার পর টাস্ক ফোর্স রেড বুক সিডি-ডিএ স্ট্যান্ডার্ড তৈরি করে। প্রথম প্রকাশিত হয় ১৯৮০ সালে। আইইসি কর্তৃক ১৯৮৭ সালে আন্তর্জাতিক মান হিসেবে আনুষ্ঠানিকভাবে এই মান গৃহীত হয় এবং ১৯৯৬ সালে বিভিন্ন সংশোধনী মানের অংশ হয়ে ওঠে।',\n",
       " 'target': 'কখন আইইসি রেড বুক সিডি-ডিএকে একটি আন্তর্জাতিক মান হিসাবে চালু করেছিল?'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T19:30:01.218655Z",
     "iopub.status.busy": "2022-09-15T19:30:01.218184Z",
     "iopub.status.idle": "2022-09-15T19:30:02.226942Z",
     "shell.execute_reply": "2022-09-15T19:30:02.225811Z",
     "shell.execute_reply.started": "2022-09-15T19:30:01.218618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "থুপির বৈজ্ঞানিক নাম কি?\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model_test.to(device)\n",
    "# # To manage one sentence\n",
    "# prompt = \"answer: Pseudozizeeria maha context: ধুপি (বৈজ্ঞানিক নাম: Pseudozizeeria maha(Kollar))[1] এক প্রজাতির ছোট আকারের প্রজাপতি যার শরীর ও ডানা হালকা ধূসর-খয়েরি বর্ণের এবং বিন্দু দেখা যায়। এরা 'লাইসিনিডি' গোত্রের এবং 'পলিয়োম্যাটিনি' উপগোত্রের সদস্য।\"\n",
    "# input_ids = tokenizer_test(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "# generated_ids = model_test.generate(input_ids,\n",
    "#                                     num_beams=7,\n",
    "#                                     num_return_sequences=7,\n",
    "# #                                     top_k=10,\n",
    "# #                                     top_p=.2,\n",
    "# #                                     temperature=0.95,\n",
    "                                    \n",
    "#                                     max_length=200)\n",
    "# for generated in generated_ids:\n",
    "#     generated_text = tokenizer_test.decode(generated,skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:45:11.486081Z",
     "iopub.status.busy": "2022-10-08T17:45:11.485544Z",
     "iopub.status.idle": "2022-10-08T17:45:11.495217Z",
     "shell.execute_reply": "2022-10-08T17:45:11.493823Z",
     "shell.execute_reply.started": "2022-10-08T17:45:11.486041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for handling multiple sentences\n",
    "def custom_gen(model, tokenizer, input_text, max_length=50, do_sample=False, temperature=None, num_beams=None, top_k=None, top_p=None, early_stopping=True, num_return_sequences=1):\n",
    "               input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
    "               generated_ids = model.generate(input_ids, max_length=max_length, do_sample=do_sample, top_k=top_k, temperature=temperature, num_beams=num_beams)\n",
    "#generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "               return generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:46:01.138689Z",
     "iopub.status.busy": "2022-10-08T17:46:01.137512Z",
     "iopub.status.idle": "2022-10-08T17:46:01.154137Z",
     "shell.execute_reply": "2022-10-08T17:46:01.152771Z",
     "shell.execute_reply.started": "2022-10-08T17:46:01.138621Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = []\n",
    "reference_question = []\n",
    "answer = []\n",
    "context = []\n",
    "#for i in range(0, len(small_dataset)):\n",
    "for i in range(0,5):\n",
    "    input_data.append('answer: ' + small_dataset[i]['answers']['text'][0]  + ' context: ' + small_dataset[i]['context'])\n",
    "    reference_question.append(small_dataset[i]['question'])\n",
    "    answer.append(small_dataset[i]['answers']['text'][0])\n",
    "    context.append(small_dataset[i]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-08T17:46:23.436659Z",
     "iopub.status.busy": "2022-10-08T17:46:23.435124Z",
     "iopub.status.idle": "2022-10-08T17:46:23.443649Z",
     "shell.execute_reply": "2022-10-08T17:46:23.442772Z",
     "shell.execute_reply.started": "2022-10-08T17:46:23.436605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['কোন দেশে নরম্যান্ডি অবস্থিত?',\n",
       " 'নরমান্ডিতে নরম্যানরা কখন ছিল?',\n",
       " 'কোন দেশ থেকে নর্সের উৎপত্তি হয়েছিল?',\n",
       " 'নর্স নেতা কে ছিলেন?',\n",
       " 'নরম্যানরা প্রথম কোন শতাব্দীতে তাদের আলাদা পরিচয় লাভ করেছিল?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T08:57:49.978126Z",
     "iopub.status.busy": "2022-09-16T08:57:49.977646Z",
     "iopub.status.idle": "2022-09-16T08:57:49.983328Z",
     "shell.execute_reply": "2022-09-16T08:57:49.981922Z",
     "shell.execute_reply.started": "2022-09-16T08:57:49.97808Z"
    }
   },
   "outputs": [],
   "source": [
    "# ('answer: ' + small_dataset[0]['answers']['text'][0]  + ' context: ' + small_dataset[0]['context'])\n",
    "# input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:06:19.067445Z",
     "iopub.status.busy": "2022-09-27T14:06:19.06705Z",
     "iopub.status.idle": "2022-09-27T14:23:09.124543Z",
     "shell.execute_reply": "2022-09-27T14:23:09.123015Z",
     "shell.execute_reply.started": "2022-09-27T14:06:19.067411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_test.to(device)\n",
    "\n",
    "# Using the custom_gen. Will have to change for our code.\n",
    "bn_pred_ques = {}\n",
    "all_generated_ids = []\n",
    "for prompt in input_data:\n",
    "#     print(prompt)\n",
    "    generated_ids = custom_gen(model_test,tokenizer_test,prompt,max_length=50,do_sample=True,top_k=40, top_p=0.95,num_return_sequences=20)\n",
    "    all_generated_ids.append(generated_ids)\n",
    "pred = []\n",
    "pred_ques =[]\n",
    "for text in all_generated_ids:\n",
    "    for generated in text:\n",
    "        generated_text = tokenizer_test.decode(generated,skip_special_tokens=True)\n",
    "#         print(generated_text)\n",
    "        pred.append(generated_text)\n",
    "        bn_pred_ques[prompt] = pred\n",
    "#     pred_ques.append(pred)\n",
    "# print(pred)\n",
    "# for generated in generated_ids:\n",
    "#     generated_text = tokenizer_test.decode(generated,skip_special_tokens=True)\n",
    "#     print(generated_text)\n",
    "#     pred.append(generated_text)\n",
    "#     bn_pred_ques[prompt] = pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reference_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:34:57.731721Z",
     "iopub.status.busy": "2022-09-27T14:34:57.730284Z",
     "iopub.status.idle": "2022-09-27T14:34:59.990809Z",
     "shell.execute_reply": "2022-09-27T14:34:59.989493Z",
     "shell.execute_reply.started": "2022-09-27T14:34:57.731669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88456e04d30241d9b5dc4428a9988443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bdd340e74040f2a31372b386dc9720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "def add_newline_to_end_of_each_sentence(x):\n",
    "        return \"\\n\".join(nltk.sent_tokenize(x))\n",
    "\n",
    "\n",
    "\n",
    "def extract_rouge_mid_statistics(dct):\n",
    "        new_dict = {}\n",
    "        for k1, v1 in dct.items():\n",
    "            mid = v1.mid\n",
    "            new_dict[k1] = {stat: round(getattr(mid, stat), 4) for stat in [\"precision\", \"recall\", \"fmeasure\"]}\n",
    "        return new_dict\n",
    "\n",
    "\n",
    "def calculate_rouge(\n",
    "        pred_lns,\n",
    "        tgt_lns,\n",
    "        use_stemmer=True,\n",
    "        rouge_keys=[\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        return_precision_and_recall=False,\n",
    "        bootstrap_aggregation=True,\n",
    "        newline_sep=True,\n",
    "       rouge_lang='bengali'\n",
    "    ):\n",
    "        \n",
    "        logger.info(\"Rouge lang: \" + str(rouge_lang))\n",
    "        scorer = rouge_scorer.RougeScorer(\n",
    "            rouge_keys, lang=rouge_lang,\n",
    "            use_stemmer=use_stemmer\n",
    "        )\n",
    "        aggregator = scoring.BootstrapAggregator()\n",
    "        for pred, tgt in zip(tgt_lns, pred_lns):\n",
    "            # rougeLsum expects \"\\n\" separated sentences within a summary\n",
    "            if newline_sep:\n",
    "                pred = add_newline_to_end_of_each_sentence(pred)\n",
    "                tgt = add_newline_to_end_of_each_sentence(tgt)\n",
    "            scores = scorer.score(pred, tgt)\n",
    "            aggregator.add_scores(scores)\n",
    "\n",
    "        if bootstrap_aggregation:\n",
    "            result = aggregator.aggregate()\n",
    "            if return_precision_and_recall:\n",
    "                return extract_rouge_mid_statistics(result)  # here we return dict\n",
    "            else:\n",
    "                results_precision = {k: round(v.mid.precision * 100, 4) for k, v in result.items()}\n",
    "                results_recall = {k: round(v.mid.recall * 100, 4) for k, v in result.items()}\n",
    "                results_fmeasure = {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "            \n",
    "            return {\n",
    "                    \"rouge1_precision\": results_precision.get('rouge1'),\n",
    "                    \"rouge1_recall\": results_recall.get('rouge1'),\n",
    "                    \"rouge1_fmeasure\": results_fmeasure.get('rouge1'),\n",
    "\n",
    "                    \"rouge2_precision\": results_precision.get('rouge2'),\n",
    "                    \"rouge2_recall\": results_recall.get('rouge2'),\n",
    "                    \"rouge2_fmeasure\": results_fmeasure.get('rouge2'),\n",
    "\n",
    "                    \"rougeL_precision\": results_precision.get('rougeL'),\n",
    "                    \"rougeL_recall\": results_recall.get('rougeL'),\n",
    "                    \"rougeL_fmeasure\": results_fmeasure.get('rougeL'),\n",
    "                \n",
    "                    \"rougeLsum_precision\": results_precision.get('rougeLsum'),\n",
    "                    \"rougeLsum_recall\": results_recall.get('rougeLsum'),\n",
    "                    \"rougeLsum_fmeasure\": results_fmeasure.get('rougeLsum'),\n",
    "                }\n",
    "#                 return {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "\n",
    "        else:\n",
    "            return aggregator._scores  # here we return defaultdict(list)\n",
    "\n",
    "        \n",
    "metric_fn = calculate_rouge\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"sacrebleu\")\n",
    "meteor = load_metric('meteor')\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:35:40.51159Z",
     "iopub.status.busy": "2022-09-27T14:35:40.511085Z",
     "iopub.status.idle": "2022-09-27T14:35:40.521047Z",
     "shell.execute_reply": "2022-09-27T14:35:40.519584Z",
     "shell.execute_reply.started": "2022-09-27T14:35:40.51155Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(ref, pred):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "        \n",
    "#     # Replace -100 in the labels as we can't decode them.\n",
    "#     labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "    \n",
    "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    \n",
    "#     decoded_preds_rouge = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     decoded_labels_rouge = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(pred, ref)\n",
    "    \n",
    "    result_rouge = metric_fn(ref, pred)\n",
    "    \n",
    "    result_bleu = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    \n",
    "    result = result_rouge\n",
    "    result[\"sacrebleu\"] = round(result_bleu['score'], 4)\n",
    "    \n",
    "    result[\"meteor\"] = round(meteor_result[\"meteor\"],4)\n",
    "    \n",
    "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "#     result = {k: round(v,4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:35:45.908586Z",
     "iopub.status.busy": "2022-09-27T14:35:45.908078Z",
     "iopub.status.idle": "2022-09-27T14:35:51.498115Z",
     "shell.execute_reply": "2022-09-27T14:35:51.496711Z",
     "shell.execute_reply.started": "2022-09-27T14:35:45.908543Z"
    }
   },
   "outputs": [],
   "source": [
    "result = compute_metrics(reference_question, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T21:44:53.509883Z",
     "iopub.status.busy": "2022-09-16T21:44:53.509502Z",
     "iopub.status.idle": "2022-09-16T21:44:53.975802Z",
     "shell.execute_reply": "2022-09-16T21:44:53.974469Z",
     "shell.execute_reply.started": "2022-09-16T21:44:53.50985Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## convert your array into a dataframe\n",
    "# df = pd.DataFrame (pred)\n",
    "df = pd.DataFrame({'Reference_question':reference_question, 'Predicted_question':pred, 'Answer': answer, 'Context': context})\n",
    "df_result = pd.DataFrame({'Rouge1_Precision': [result['rouge1_precision']], 'Rouge1_Recall': [result['rouge1_recall']],\n",
    "                         'Rouge1_fmeasure': [result['rouge1_fmeasure']],\n",
    "                         'Rouge2_Precision': [result['rouge2_precision']], 'Rouge2_Recall': [result['rouge2_recall']],\n",
    "                         'Rouge2_fmeasure': [result['rouge2_fmeasure']],\n",
    "                         'RougeL_Precision': [result['rougeL_precision']], 'RougeL_Recall': [result['rougeL_recall']],\n",
    "                         'RougeL_fmeasure': [result['rougeL_fmeasure']],\n",
    "                         'RougeLsum_Precision': [result['rougeLsum_precision']], 'RougeLsum_Recall': [result['rougeLsum_recall']],\n",
    "                         'RougeLsum_fmeasure': [result['rougeLsum_fmeasure']],\n",
    "                         'SacreBleu': [result['sacrebleu']], 'Meteor': [result['meteor']]})\n",
    "## save to xlsx file\n",
    "\n",
    "filepath = 'top_k401_top_p095.xlsx'\n",
    "writer = pd.ExcelWriter(filepath, engine='xlsxwriter')\n",
    "df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "df_result.to_excel(writer, index=False, sheet_name='Result')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T14:35:56.939722Z",
     "iopub.status.busy": "2022-09-27T14:35:56.939298Z",
     "iopub.status.idle": "2022-09-27T14:36:00.038765Z",
     "shell.execute_reply": "2022-09-27T14:36:00.037482Z",
     "shell.execute_reply.started": "2022-09-27T14:35:56.939687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k = 40 top_p=0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 25.8191,\n",
       " 'rouge1_recall': 26.9641,\n",
       " 'rouge1_fmeasure': 25.4519,\n",
       " 'rouge2_precision': 8.7354,\n",
       " 'rouge2_recall': 9.2826,\n",
       " 'rouge2_fmeasure': 8.6548,\n",
       " 'rougeL_precision': 24.4047,\n",
       " 'rougeL_recall': 25.5485,\n",
       " 'rougeL_fmeasure': 24.0773,\n",
       " 'rougeLsum_precision': 24.4055,\n",
       " 'rougeLsum_recall': 25.579,\n",
       " 'rougeLsum_fmeasure': 24.1118,\n",
       " 'sacrebleu': 4.8759,\n",
       " 'meteor': 0.1388}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"top_k = 40 top_p=0.95\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T21:22:31.427608Z",
     "iopub.status.busy": "2022-09-16T21:22:31.42693Z",
     "iopub.status.idle": "2022-09-16T21:22:34.620823Z",
     "shell.execute_reply": "2022-09-16T21:22:34.619521Z",
     "shell.execute_reply.started": "2022-09-16T21:22:31.427553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_p = 1 temperature=0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 25.3467,\n",
       " 'rouge1_recall': 26.6861,\n",
       " 'rouge1_fmeasure': 25.1342,\n",
       " 'rouge2_precision': 8.1951,\n",
       " 'rouge2_recall': 8.8998,\n",
       " 'rouge2_fmeasure': 8.2359,\n",
       " 'rougeL_precision': 24.0994,\n",
       " 'rougeL_recall': 25.494,\n",
       " 'rougeL_fmeasure': 23.9426,\n",
       " 'rougeLsum_precision': 24.1085,\n",
       " 'rougeLsum_recall': 25.5208,\n",
       " 'rougeLsum_fmeasure': 23.9557,\n",
       " 'sacrebleu': 4.4088,\n",
       " 'meteor': 0.1363}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"top_p = 1 temperature=0.95\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T20:50:39.008862Z",
     "iopub.status.busy": "2022-09-16T20:50:39.008414Z",
     "iopub.status.idle": "2022-09-16T20:50:42.282725Z",
     "shell.execute_reply": "2022-09-16T20:50:42.281666Z",
     "shell.execute_reply.started": "2022-09-16T20:50:39.008817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k = 100 top_p = 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 24.3675,\n",
       " 'rouge1_recall': 25.1895,\n",
       " 'rouge1_fmeasure': 23.8669,\n",
       " 'rouge2_precision': 7.7654,\n",
       " 'rouge2_recall': 8.3323,\n",
       " 'rouge2_fmeasure': 7.7053,\n",
       " 'rougeL_precision': 23.1111,\n",
       " 'rougeL_recall': 23.9016,\n",
       " 'rougeL_fmeasure': 22.633,\n",
       " 'rougeLsum_precision': 23.0785,\n",
       " 'rougeLsum_recall': 23.8937,\n",
       " 'rougeLsum_fmeasure': 22.6392,\n",
       " 'sacrebleu': 4.09,\n",
       " 'meteor': 0.1338}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"top_k=100 top_p=0.95\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T20:30:23.493673Z",
     "iopub.status.busy": "2022-09-16T20:30:23.493186Z",
     "iopub.status.idle": "2022-09-16T20:30:26.627072Z",
     "shell.execute_reply": "2022-09-16T20:30:26.625668Z",
     "shell.execute_reply.started": "2022-09-16T20:30:23.493632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_BEAMS=10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 33.2037,\n",
       " 'rouge1_recall': 35.3239,\n",
       " 'rouge1_fmeasure': 33.1948,\n",
       " 'rouge2_precision': 14.1174,\n",
       " 'rouge2_recall': 15.4019,\n",
       " 'rouge2_fmeasure': 14.2558,\n",
       " 'rougeL_precision': 31.4554,\n",
       " 'rougeL_recall': 33.5326,\n",
       " 'rougeL_fmeasure': 31.4925,\n",
       " 'rougeLsum_precision': 31.3992,\n",
       " 'rougeLsum_recall': 33.4731,\n",
       " 'rougeLsum_fmeasure': 31.4722,\n",
       " 'sacrebleu': 8.1095,\n",
       " 'meteor': 0.1794}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"NUM_BEAMS=10\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T19:35:46.015879Z",
     "iopub.status.busy": "2022-09-16T19:35:46.015499Z",
     "iopub.status.idle": "2022-09-16T19:35:49.142762Z",
     "shell.execute_reply": "2022-09-16T19:35:49.141382Z",
     "shell.execute_reply.started": "2022-09-16T19:35:46.015845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_BEAMS=7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 32.9489,\n",
       " 'rouge1_recall': 35.2039,\n",
       " 'rouge1_fmeasure': 33.0053,\n",
       " 'rouge2_precision': 13.9216,\n",
       " 'rouge2_recall': 15.2639,\n",
       " 'rouge2_fmeasure': 14.0935,\n",
       " 'rougeL_precision': 31.2152,\n",
       " 'rougeL_recall': 33.4568,\n",
       " 'rougeL_fmeasure': 31.3553,\n",
       " 'rougeLsum_precision': 31.1402,\n",
       " 'rougeLsum_recall': 33.4541,\n",
       " 'rougeLsum_fmeasure': 31.3185,\n",
       " 'sacrebleu': 8.1074,\n",
       " 'meteor': 0.1782}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"NUM_BEAMS=7\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T18:27:20.207232Z",
     "iopub.status.busy": "2022-09-16T18:27:20.206718Z",
     "iopub.status.idle": "2022-09-16T18:27:23.366562Z",
     "shell.execute_reply": "2022-09-16T18:27:23.365607Z",
     "shell.execute_reply.started": "2022-09-16T18:27:20.207194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_BEAMS=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 32.762,\n",
       " 'rouge1_recall': 35.2326,\n",
       " 'rouge1_fmeasure': 32.9817,\n",
       " 'rouge2_precision': 13.9094,\n",
       " 'rouge2_recall': 15.3718,\n",
       " 'rouge2_fmeasure': 14.1434,\n",
       " 'rougeL_precision': 31.159,\n",
       " 'rougeL_recall': 33.5899,\n",
       " 'rougeL_fmeasure': 31.4034,\n",
       " 'rougeLsum_precision': 31.1237,\n",
       " 'rougeLsum_recall': 33.547,\n",
       " 'rougeLsum_fmeasure': 31.3612,\n",
       " 'sacrebleu': 8.0115,\n",
       " 'meteor': 0.1767}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"NUM_BEAMS=5\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T17:51:35.185771Z",
     "iopub.status.busy": "2022-09-16T17:51:35.185179Z",
     "iopub.status.idle": "2022-09-16T17:51:38.322978Z",
     "shell.execute_reply": "2022-09-16T17:51:38.321363Z",
     "shell.execute_reply.started": "2022-09-16T17:51:35.18573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_BEAMS=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1_precision': 32.3829,\n",
       " 'rouge1_recall': 34.7771,\n",
       " 'rouge1_fmeasure': 32.5061,\n",
       " 'rouge2_precision': 13.6391,\n",
       " 'rouge2_recall': 14.8435,\n",
       " 'rouge2_fmeasure': 13.7345,\n",
       " 'rougeL_precision': 30.8244,\n",
       " 'rougeL_recall': 33.1571,\n",
       " 'rougeL_fmeasure': 30.9929,\n",
       " 'rougeLsum_precision': 30.8117,\n",
       " 'rougeLsum_recall': 33.1441,\n",
       " 'rougeLsum_fmeasure': 30.9659,\n",
       " 'sacrebleu': 7.7325,\n",
       " 'meteor': 0.1743}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = compute_metrics(reference_question, pred)\n",
    "print(\"NUM_BEAMS=3\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
